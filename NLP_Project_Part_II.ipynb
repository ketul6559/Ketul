{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Nw8dyoSrdtE",
    "outputId": "555afbcb-d6a7-4320-a05c-4030198d869a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import json\n",
    "import pickle\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zWrLSzXmrdtx"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "937a766hrdt0"
   },
   "outputs": [],
   "source": [
    "gl_bot_file = open('GL Bot.json').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "on80O9DPrdt2"
   },
   "outputs": [],
   "source": [
    "gl_bot = json.loads(gl_bot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoYNsNT5rdt3",
    "outputId": "b062860c-6d4b-4de0-9286-4dfbb92ecfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'Intro',\n",
       "   'patterns': ['hi',\n",
       "    'how are you',\n",
       "    'is anyone there',\n",
       "    'hello',\n",
       "    'whats up',\n",
       "    'hey',\n",
       "    'yo',\n",
       "    'listen',\n",
       "    'please help me',\n",
       "    'i am learner from',\n",
       "    'i belong to',\n",
       "    'aiml batch',\n",
       "    'aifl batch',\n",
       "    'i am from',\n",
       "    'my pm is',\n",
       "    'blended',\n",
       "    'online',\n",
       "    'i am from',\n",
       "    'hey ya',\n",
       "    'ml batch',\n",
       "    'ai batch',\n",
       "    'good morning',\n",
       "    'this is',\n",
       "    'talking to you for first time'],\n",
       "   'responses': ['Hello! how can i help you ?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Exit',\n",
       "   'patterns': ['thank you',\n",
       "    'thanks',\n",
       "    'cya',\n",
       "    'see you',\n",
       "    'later',\n",
       "    'see you later',\n",
       "    'goodbye',\n",
       "    'i am leaving',\n",
       "    'have a Good day',\n",
       "    'you helped me',\n",
       "    'thanks a lot',\n",
       "    'thanks a ton',\n",
       "    'you are the best',\n",
       "    'great help',\n",
       "    'too good',\n",
       "    'have a gread day',\n",
       "    'tata',\n",
       "    'see you around',\n",
       "    'you are a good learning buddy'],\n",
       "   'responses': ['I hope I was able to assist you, Good Bye'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Olympus',\n",
       "   'patterns': ['olympus',\n",
       "    'explain me how olympus works',\n",
       "    'I am not able to understand olympus',\n",
       "    'olympus window not working',\n",
       "    'no access to olympus',\n",
       "    'unable to see link in olympus',\n",
       "    'no link visible on olympus',\n",
       "    'whom to contact for olympus',\n",
       "    'lot of problem with olympus',\n",
       "    'olypus is not a good tool',\n",
       "    'lot of problems with olympus',\n",
       "    'how to use olympus',\n",
       "    'unable to understand olympus',\n",
       "    'tutorial on olympus',\n",
       "    'teach me olympus'],\n",
       "   'responses': ['Link: Olympus wiki'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'SL',\n",
       "   'patterns': ['i am not able to understand svm',\n",
       "    'explain me how machine learning works',\n",
       "    'i am not able to understand naive bayes',\n",
       "    'i am not able to understand logistic regression',\n",
       "    'i am not able to understand ensemble techb=niques',\n",
       "    'i am not able to understand knn',\n",
       "    'i am not able to understand knn imputer',\n",
       "    'i am not able to understand cross validation',\n",
       "    'i am not able to understand boosting',\n",
       "    'i am not able to understand random forest',\n",
       "    'i am not able to understand ada boosting',\n",
       "    'i am not able to understand gradient boosting',\n",
       "    'i am not able to understand linear regression',\n",
       "    'i am not able to understand decision tree',\n",
       "    'i am not able to understand support vector machine',\n",
       "    'machine learning',\n",
       "    'ML',\n",
       "    'SL',\n",
       "    'supervised learning',\n",
       "    'knn',\n",
       "    'logistic regression',\n",
       "    'regression',\n",
       "    'classification',\n",
       "    'naive bayes',\n",
       "    'nb',\n",
       "    'ensemble techniques',\n",
       "    'bagging',\n",
       "    'boosting',\n",
       "    'ada boosting',\n",
       "    'ada',\n",
       "    'gradient boosting',\n",
       "    'hyper parameters'],\n",
       "   'responses': ['Link: Machine Learning wiki '],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'NN',\n",
       "   'patterns': ['what is deep learning',\n",
       "    'unable to understand deep learning',\n",
       "    'explain me how deep learning works',\n",
       "    'i am not able to understand deep learning',\n",
       "    'not able to understand neural nets',\n",
       "    'very diffult to understand neural nets',\n",
       "    'unable to understand neural nets',\n",
       "    'what is forward propagation',\n",
       "    'what is backward propagation',\n",
       "    'gradient decent',\n",
       "    'ann',\n",
       "    'artificial intelligence',\n",
       "    'artificial neural networks',\n",
       "    'weights',\n",
       "    'activation function',\n",
       "    'hidden layers',\n",
       "    'softmax',\n",
       "    'sigmoid',\n",
       "    'relu',\n",
       "    'optimizer',\n",
       "    'forward propagation',\n",
       "    'backward propagation',\n",
       "    'epochs',\n",
       "    'epoch',\n",
       "    'what is an epoch',\n",
       "    'adam',\n",
       "    'sgd'],\n",
       "   'responses': ['Link: Neural Nets wiki'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Bot',\n",
       "   'patterns': ['what is your name',\n",
       "    'who are you',\n",
       "    'your name',\n",
       "    'what is your identity',\n",
       "    'name please',\n",
       "    'when are your hours of opertions',\n",
       "    'what are your working hours',\n",
       "    'hours of operation',\n",
       "    'working hours',\n",
       "    'hours'],\n",
       "   'responses': ['I am your virtual learning assistant'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Profane',\n",
       "   'patterns': ['what the hell',\n",
       "    'bloody stupid bot',\n",
       "    'do you think you are very smart',\n",
       "    'screw you',\n",
       "    'i hate you',\n",
       "    'you are stupid',\n",
       "    'jerk',\n",
       "    'you are a joke',\n",
       "    'wasted',\n",
       "    'you are dull',\n",
       "    'brainless',\n",
       "    'go to hell',\n",
       "    'you are crap',\n",
       "    'useless piece of shit'],\n",
       "   'responses': ['Please use respectful words'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'Ticket',\n",
       "   'patterns': ['my problem is not solved',\n",
       "    'you did not help me',\n",
       "    'not a good solution',\n",
       "    'did not work for me',\n",
       "    'answer is not right',\n",
       "    'wrong solution',\n",
       "    'bad solution',\n",
       "    'not good solution',\n",
       "    'no help',\n",
       "    'wasted my time',\n",
       "    'useless bot',\n",
       "    'create a ticket'],\n",
       "   'responses': ['Tarnsferring the request to your PM'],\n",
       "   'context_set': ''}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5cPZltSrdt-",
    "outputId": "53a19cc9-b25f-410b-ba12-d499e08ab52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['hi'], 'Intro'), (['how', 'are', 'you'], 'Intro'), (['is', 'anyone', 'there'], 'Intro'), (['hello'], 'Intro'), (['whats', 'up'], 'Intro'), (['hey'], 'Intro'), (['yo'], 'Intro'), (['listen'], 'Intro'), (['please', 'help', 'me'], 'Intro'), (['i', 'am', 'learner', 'from'], 'Intro'), (['i', 'belong', 'to'], 'Intro'), (['aiml', 'batch'], 'Intro'), (['aifl', 'batch'], 'Intro'), (['i', 'am', 'from'], 'Intro'), (['my', 'pm', 'is'], 'Intro'), (['blended'], 'Intro'), (['online'], 'Intro'), (['i', 'am', 'from'], 'Intro'), (['hey', 'ya'], 'Intro'), (['ml', 'batch'], 'Intro'), (['ai', 'batch'], 'Intro'), (['good', 'morning'], 'Intro'), (['this', 'is'], 'Intro'), (['talking', 'to', 'you', 'for', 'first', 'time'], 'Intro'), (['thank', 'you'], 'Exit'), (['thanks'], 'Exit'), (['cya'], 'Exit'), (['see', 'you'], 'Exit'), (['later'], 'Exit'), (['see', 'you', 'later'], 'Exit'), (['goodbye'], 'Exit'), (['i', 'am', 'leaving'], 'Exit'), (['have', 'a', 'Good', 'day'], 'Exit'), (['you', 'helped', 'me'], 'Exit'), (['thanks', 'a', 'lot'], 'Exit'), (['thanks', 'a', 'ton'], 'Exit'), (['you', 'are', 'the', 'best'], 'Exit'), (['great', 'help'], 'Exit'), (['too', 'good'], 'Exit'), (['have', 'a', 'gread', 'day'], 'Exit'), (['tata'], 'Exit'), (['see', 'you', 'around'], 'Exit'), (['you', 'are', 'a', 'good', 'learning', 'buddy'], 'Exit'), (['olympus'], 'Olympus'), (['explain', 'me', 'how', 'olympus', 'works'], 'Olympus'), (['I', 'am', 'not', 'able', 'to', 'understand', 'olympus'], 'Olympus'), (['olympus', 'window', 'not', 'working'], 'Olympus'), (['no', 'access', 'to', 'olympus'], 'Olympus'), (['unable', 'to', 'see', 'link', 'in', 'olympus'], 'Olympus'), (['no', 'link', 'visible', 'on', 'olympus'], 'Olympus'), (['whom', 'to', 'contact', 'for', 'olympus'], 'Olympus'), (['lot', 'of', 'problem', 'with', 'olympus'], 'Olympus'), (['olypus', 'is', 'not', 'a', 'good', 'tool'], 'Olympus'), (['lot', 'of', 'problems', 'with', 'olympus'], 'Olympus'), (['how', 'to', 'use', 'olympus'], 'Olympus'), (['unable', 'to', 'understand', 'olympus'], 'Olympus'), (['tutorial', 'on', 'olympus'], 'Olympus'), (['teach', 'me', 'olympus'], 'Olympus'), (['i', 'am', 'not', 'able', 'to', 'understand', 'svm'], 'SL'), (['explain', 'me', 'how', 'machine', 'learning', 'works'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'naive', 'bayes'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'logistic', 'regression'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'ensemble', 'techb=niques'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'knn'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'imputer'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'cross', 'validation'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'boosting'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'random', 'forest'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'ada', 'boosting'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'gradient', 'boosting'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'linear', 'regression'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'decision', 'tree'], 'SL'), (['i', 'am', 'not', 'able', 'to', 'understand', 'support', 'vector', 'machine'], 'SL'), (['machine', 'learning'], 'SL'), (['ML'], 'SL'), (['SL'], 'SL'), (['supervised', 'learning'], 'SL'), (['knn'], 'SL'), (['logistic', 'regression'], 'SL'), (['regression'], 'SL'), (['classification'], 'SL'), (['naive', 'bayes'], 'SL'), (['nb'], 'SL'), (['ensemble', 'techniques'], 'SL'), (['bagging'], 'SL'), (['boosting'], 'SL'), (['ada', 'boosting'], 'SL'), (['ada'], 'SL'), (['gradient', 'boosting'], 'SL'), (['hyper', 'parameters'], 'SL'), (['what', 'is', 'deep', 'learning'], 'NN'), (['unable', 'to', 'understand', 'deep', 'learning'], 'NN'), (['explain', 'me', 'how', 'deep', 'learning', 'works'], 'NN'), (['i', 'am', 'not', 'able', 'to', 'understand', 'deep', 'learning'], 'NN'), (['not', 'able', 'to', 'understand', 'neural', 'nets'], 'NN'), (['very', 'diffult', 'to', 'understand', 'neural', 'nets'], 'NN'), (['unable', 'to', 'understand', 'neural', 'nets'], 'NN'), (['what', 'is', 'forward', 'propagation'], 'NN'), (['what', 'is', 'backward', 'propagation'], 'NN'), (['gradient', 'decent'], 'NN'), (['ann'], 'NN'), (['artificial', 'intelligence'], 'NN'), (['artificial', 'neural', 'networks'], 'NN'), (['weights'], 'NN'), (['activation', 'function'], 'NN'), (['hidden', 'layers'], 'NN'), (['softmax'], 'NN'), (['sigmoid'], 'NN'), (['relu'], 'NN'), (['optimizer'], 'NN'), (['forward', 'propagation'], 'NN'), (['backward', 'propagation'], 'NN'), (['epochs'], 'NN'), (['epoch'], 'NN'), (['what', 'is', 'an', 'epoch'], 'NN'), (['adam'], 'NN'), (['sgd'], 'NN'), (['what', 'is', 'your', 'name'], 'Bot'), (['who', 'are', 'you'], 'Bot'), (['your', 'name'], 'Bot'), (['what', 'is', 'your', 'identity'], 'Bot'), (['name', 'please'], 'Bot'), (['when', 'are', 'your', 'hours', 'of', 'opertions'], 'Bot'), (['what', 'are', 'your', 'working', 'hours'], 'Bot'), (['hours', 'of', 'operation'], 'Bot'), (['working', 'hours'], 'Bot'), (['hours'], 'Bot'), (['what', 'the', 'hell'], 'Profane'), (['bloody', 'stupid', 'bot'], 'Profane'), (['do', 'you', 'think', 'you', 'are', 'very', 'smart'], 'Profane'), (['screw', 'you'], 'Profane'), (['i', 'hate', 'you'], 'Profane'), (['you', 'are', 'stupid'], 'Profane'), (['jerk'], 'Profane'), (['you', 'are', 'a', 'joke'], 'Profane'), (['wasted'], 'Profane'), (['you', 'are', 'dull'], 'Profane'), (['brainless'], 'Profane'), (['go', 'to', 'hell'], 'Profane'), (['you', 'are', 'crap'], 'Profane'), (['useless', 'piece', 'of', 'shit'], 'Profane'), (['my', 'problem', 'is', 'not', 'solved'], 'Ticket'), (['you', 'did', 'not', 'help', 'me'], 'Ticket'), (['not', 'a', 'good', 'solution'], 'Ticket'), (['did', 'not', 'work', 'for', 'me'], 'Ticket'), (['answer', 'is', 'not', 'right'], 'Ticket'), (['wrong', 'solution'], 'Ticket'), (['bad', 'solution'], 'Ticket'), (['not', 'good', 'solution'], 'Ticket'), (['no', 'help'], 'Ticket'), (['wasted', 'my', 'time'], 'Ticket'), (['useless', 'bot'], 'Ticket'), (['create', 'a', 'ticket'], 'Ticket')]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_letters = ['!', '?', ',', '.']\n",
    "\n",
    "for intent in gl_bot['intents']:    \n",
    "    for pattern in intent['patterns']:\n",
    "        word = nltk.word_tokenize(pattern)\n",
    "        words.extend(word)\n",
    "        \n",
    "        documents.append((word, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pW-EWveArduB",
    "outputId": "752d4358-23d2-4fb6-edcc-59bbc4bbd557"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'able',\n",
       " 'access',\n",
       " 'activation',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'ai',\n",
       " 'aifl',\n",
       " 'aiml',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ann',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'are',\n",
       " 'around',\n",
       " 'artificial',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bagging',\n",
       " 'batch',\n",
       " 'bayes',\n",
       " 'belong',\n",
       " 'best',\n",
       " 'blended',\n",
       " 'bloody',\n",
       " 'boosting',\n",
       " 'bot',\n",
       " 'brainless',\n",
       " 'buddy',\n",
       " 'classification',\n",
       " 'contact',\n",
       " 'crap',\n",
       " 'create',\n",
       " 'cross',\n",
       " 'cya',\n",
       " 'day',\n",
       " 'decent',\n",
       " 'decision',\n",
       " 'deep',\n",
       " 'did',\n",
       " 'diffult',\n",
       " 'do',\n",
       " 'dull',\n",
       " 'ensemble',\n",
       " 'epoch',\n",
       " 'explain',\n",
       " 'first',\n",
       " 'for',\n",
       " 'forest',\n",
       " 'forward',\n",
       " 'from',\n",
       " 'function',\n",
       " 'go',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'gradient',\n",
       " 'gread',\n",
       " 'great',\n",
       " 'hate',\n",
       " 'have',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hidden',\n",
       " 'hour',\n",
       " 'how',\n",
       " 'hyper',\n",
       " 'i',\n",
       " 'identity',\n",
       " 'imputer',\n",
       " 'in',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'jerk',\n",
       " 'joke',\n",
       " 'knn',\n",
       " 'later',\n",
       " 'layer',\n",
       " 'learner',\n",
       " 'learning',\n",
       " 'leaving',\n",
       " 'linear',\n",
       " 'link',\n",
       " 'listen',\n",
       " 'logistic',\n",
       " 'lot',\n",
       " 'machine',\n",
       " 'me',\n",
       " 'ml',\n",
       " 'morning',\n",
       " 'my',\n",
       " 'naive',\n",
       " 'name',\n",
       " 'nb',\n",
       " 'net',\n",
       " 'network',\n",
       " 'neural',\n",
       " 'no',\n",
       " 'not',\n",
       " 'of',\n",
       " 'olympus',\n",
       " 'olypus',\n",
       " 'on',\n",
       " 'online',\n",
       " 'operation',\n",
       " 'opertions',\n",
       " 'optimizer',\n",
       " 'parameter',\n",
       " 'piece',\n",
       " 'please',\n",
       " 'pm',\n",
       " 'problem',\n",
       " 'propagation',\n",
       " 'random',\n",
       " 'regression',\n",
       " 'relu',\n",
       " 'right',\n",
       " 'screw',\n",
       " 'see',\n",
       " 'sgd',\n",
       " 'shit',\n",
       " 'sigmoid',\n",
       " 'sl',\n",
       " 'smart',\n",
       " 'softmax',\n",
       " 'solution',\n",
       " 'solved',\n",
       " 'stupid',\n",
       " 'supervised',\n",
       " 'support',\n",
       " 'svm',\n",
       " 'talking',\n",
       " 'tata',\n",
       " 'teach',\n",
       " 'techb=niques',\n",
       " 'technique',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'the',\n",
       " 'there',\n",
       " 'think',\n",
       " 'this',\n",
       " 'ticket',\n",
       " 'time',\n",
       " 'to',\n",
       " 'ton',\n",
       " 'too',\n",
       " 'tool',\n",
       " 'tree',\n",
       " 'tutorial',\n",
       " 'unable',\n",
       " 'understand',\n",
       " 'up',\n",
       " 'use',\n",
       " 'useless',\n",
       " 'validation',\n",
       " 'vector',\n",
       " 'very',\n",
       " 'visible',\n",
       " 'wasted',\n",
       " 'weight',\n",
       " 'what',\n",
       " 'whats',\n",
       " 'when',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'window',\n",
       " 'with',\n",
       " 'work',\n",
       " 'working',\n",
       " 'wrong',\n",
       " 'ya',\n",
       " 'yo',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_letters]\n",
    "words = sorted(list(set(words)))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5aJ6hdHrduD",
    "outputId": "3f024a64-86be-446a-a124-42f553cde004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bot', 'Exit', 'Intro', 'NN', 'Olympus', 'Profane', 'SL', 'Ticket']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(set(classes)))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-cEKaojrduE",
    "outputId": "d77d509f-ac8c-434e-980e-3e1ecb3ec914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmaHv1GJrduG",
    "outputId": "c23363a8-c0d9-4972-c259-e75fbe35825e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SBZyhlpcrduH"
   },
   "outputs": [],
   "source": [
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pcNOhMZZrduJ"
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "output_empty = [0] * len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MNMryvCorduL"
   },
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    bag = []\n",
    "    word_pattenrs = doc[0]\n",
    "    word_pattenrs = [lemmatizer.lemmatize(word.lower()) for word in word_pattenrs]\n",
    "    \n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_pattenrs else bag.append(0)\n",
    "        \n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype = 'object')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "69pU19BerduP"
   },
   "outputs": [],
   "source": [
    "X_train = list(training[:, 0])\n",
    "y_train = list(training[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cw_H9apGs1iJ",
    "outputId": "a966a548-3b63-41ca-d543-727aa86b6c50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0]), len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hocn8-VcsBsA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GLzOE2L_snDJ"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape = (len(X_train[0]),), activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(y_train[0]), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esjA4xs3tagE",
    "outputId": "da459c4c-cff4-43b6-b610-6d92f86bd3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               23040     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 31,816\n",
      "Trainable params: 31,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW6rjX4zuag5",
    "outputId": "16371099-b107-4ede-e276-7a3bca7bf8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 2.1236 - accuracy: 0.1082\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.0429 - accuracy: 0.2100\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.9847 - accuracy: 0.2324\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.9623 - accuracy: 0.2459\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.8720 - accuracy: 0.2705\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.8506 - accuracy: 0.2877\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7717 - accuracy: 0.3443\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6660 - accuracy: 0.3769\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6092 - accuracy: 0.4634\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.5770 - accuracy: 0.4642\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.5434 - accuracy: 0.4443\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.5207 - accuracy: 0.4412\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4038 - accuracy: 0.4766\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3148 - accuracy: 0.6201\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3934 - accuracy: 0.4875\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1754 - accuracy: 0.6326\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1271 - accuracy: 0.6421\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9663 - accuracy: 0.7283\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9178 - accuracy: 0.7359\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.7240\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7973 - accuracy: 0.7886\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.7844\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.8560\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.8215\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7885\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8601\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8548\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8586\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.8394\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8981\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8365\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8485\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.9175\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.9319\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9401\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.9394\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8838\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9521\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.9162\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9586\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.9283\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9756\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9052\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9415\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9780\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9649\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9484\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9309\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9382\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9711\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9481\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9740\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9764\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9988\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9837\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9448\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9846\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9782\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9851\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9601\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9967\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9969\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9824\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9838\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9858\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9802\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9785\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9927\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9741\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9813\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9984\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9701\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9937\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9805\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9708\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9803\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9968\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9920\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9933\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9704\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9663\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9964\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9964\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9964\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9764\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9885\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9980\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9969\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9627\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9797\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9931\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9761\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9894\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9696\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9941\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9889\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9685\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9725\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9880\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9856\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9912\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9797\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9980\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9831\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9825\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9964\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9844\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9860\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9934\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9553\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9921\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9969\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9931\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9926\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9937\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9920\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9984\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9941\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9872\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9969\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 0.9874\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9964\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9781\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9964\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9980\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9920\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9865\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9729\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9975\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9855\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9888\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9889\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9855\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9964\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9797\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9856\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9649\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9856\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9969\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9920\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9797\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9905\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9908\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9856\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9931\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9964\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9797\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9819\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9836\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9781\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9905\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9939\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9975\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9904\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(np.array(X_train), np.array(y_train), epochs = 200, batch_size = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rFDQUPtOu38I"
   },
   "outputs": [],
   "source": [
    "model.save('chatbot.h5', hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s, W):\n",
    "    bag = [0 for _ in range(len(W))]\n",
    "     \n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    \n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(W):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "                \n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Chat with BOT (type: stop to quit)\")\n",
    "    print('If answer is not right (type: *)')\n",
    "    \n",
    "    while True:\n",
    "        inp = input('\\n\\nYou:')\n",
    "        if inp.lower() == '*':\n",
    "            print('Bot : Please rephrase your question and try again')\n",
    "        if inp.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        results_temp = np.concatenate((bag_of_words(inp, words)), None)\n",
    "        results = model.predict(np.array([results_temp]))\n",
    "        results_index = np.argmax(results)\n",
    "        tag = classes[results_index]\n",
    "        \n",
    "        for tg in gl_bot['intents']:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['responses']\n",
    "        print(random.choice(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with BOT (type: stop to quit)\n",
      "If answer is not right (type: *)\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project - Part II.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
